<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>消息队列 on 拳拳到肉</title>
    <link>/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
    <description>Recent content in 消息队列 on 拳拳到肉</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sat, 06 Jun 2020 07:37:42 +0800</lastBuildDate>
    
	<atom:link href="/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kafka Controller 模块（一）概述</title>
      <link>/blog/kafka-controller-%E6%A8%A1%E5%9D%97%E4%B8%80%E6%A6%82%E8%BF%B0/</link>
      <pubDate>Sat, 06 Jun 2020 07:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-controller-%E6%A8%A1%E5%9D%97%E4%B8%80%E6%A6%82%E8%BF%B0/</guid>
      <description>概述 在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（KafkaController），它负责管理整个集群中所有分区和副本</description>
    </item>
    
    <item>
      <title>Kafka 副本模块 ReplicaManager</title>
      <link>/blog/kafka-%E5%89%AF%E6%9C%AC%E6%A8%A1%E5%9D%97-replicamanager/</link>
      <pubDate>Mon, 01 Jun 2020 10:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E5%89%AF%E6%9C%AC%E6%A8%A1%E5%9D%97-replicamanager/</guid>
      <description>Kafka 的 Replication Mechanism 是为了保证 Kafka 的高可用性，也就是说一个每个分区可以有多个副本，并且会其副本集合中(AR) 选出一个副本作为 Leader 副本，所有的读写请求都由选举出来的 Leader 副本处理</description>
    </item>
    
    <item>
      <title>Kafka 时间轮 Java 版本实现</title>
      <link>/blog/kafka-%E6%97%B6%E9%97%B4%E8%BD%AE-java-%E7%89%88%E6%9C%AC%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Thu, 14 May 2020 20:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%97%B6%E9%97%B4%E8%BD%AE-java-%E7%89%88%E6%9C%AC%E5%AE%9E%E7%8E%B0/</guid>
      <description>概述 用Java 简单实现了 Kafka 中的时间轮。具体文章请看 Kafka 延迟操作（一）DelayedOperationPurgatory 具体实现 时间轮实现 public class TimingWheel</description>
    </item>
    
    <item>
      <title>Kafka 延迟操作（二）DelayedProduce</title>
      <link>/blog/kafka-%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C%E4%BA%8Cdelayedproduce/</link>
      <pubDate>Thu, 07 May 2020 18:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C%E4%BA%8Cdelayedproduce/</guid>
      <description>Kafka Producer ack 设置为 all，需要所有的ISR 都接收到这条消息后才会返回。这里就用到了延迟操作。</description>
    </item>
    
    <item>
      <title>Kafka 延迟操作（一）DelayedOperationPurgatory</title>
      <link>/blog/kafka-%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C%E4%B8%80delayedoperationpurgatory/</link>
      <pubDate>Thu, 07 May 2020 08:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C%E4%B8%80delayedoperationpurgatory/</guid>
      <description>概述 Kafka中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等，DelayedOperationPurgatory 则是来管理这些延</description>
    </item>
    
    <item>
      <title>Kafka 日志模块（四）LogManager</title>
      <link>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E5%9B%9Blogmanager/</link>
      <pubDate>Tue, 05 May 2020 08:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E5%9B%9Blogmanager/</guid>
      <description>Kafka 的所有的消息都是通过日志来存储的，它是通过 LogManager 来进行初始化的，Log 类是真正操作日志的，LogManager 是用来管理 Log 的。</description>
    </item>
    
    <item>
      <title>Kafka 日志模块（三）索引</title>
      <link>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%B8%89%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Sun, 03 May 2020 16:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%B8%89%E7%B4%A2%E5%BC%95/</guid>
      <description>1. 概述 在 Kafka 日志模块（二）LogSegment 一文中说过，每次添加 log 的时候都会，添加相对应的索引，索引是用来快速定义 message (通过二分查找)。 2. 源码</description>
    </item>
    
    <item>
      <title>Kafka 日志模块（二）LogSegment</title>
      <link>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%BA%8Clogsegment/</link>
      <pubDate>Sun, 03 May 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%BA%8Clogsegment/</guid>
      <description>概述 在 Kafka 日志模块（一）Log 一文中讲到了Kafka 为了防止日志文件太大，把日志文件分成多个 LogSegment ，而在每个 Segment 中又有索引文件，为了快速查找所需要的</description>
    </item>
    
    <item>
      <title>Kafka 日志模块（一）Log</title>
      <link>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%B8%80log/</link>
      <pubDate>Fri, 01 May 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E4%B8%80log/</guid>
      <description>Kafka 使用&lt;code&gt;日志文件&lt;/code&gt;的方式保存生产者发送的消息。每条消息都有一个 &lt;code&gt;offset&lt;/code&gt; 值来标识它在分区中的偏移量，这个offset 是&lt;code&gt;逻辑值&lt;/code&gt;，并不是消息实际存放的物理地址。</description>
    </item>
    
    <item>
      <title>Kafka 源码环境 Log 输出问题</title>
      <link>/blog/kafka-%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83-log-%E8%BE%93%E5%87%BA%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 27 Apr 2020 10:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83-log-%E8%BE%93%E5%87%BA%E9%97%AE%E9%A2%98/</guid>
      <description>① 在 Modules 中找到core 加入 slf4j-log4j12 和 log4j ② 加入 log4j.properties</description>
    </item>
    
    <item>
      <title>Kafka 服务端（三）kafka-server-start.sh</title>
      <link>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%89kafka-server-start.sh/</link>
      <pubDate>Sun, 26 Apr 2020 09:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%89kafka-server-start.sh/</guid>
      <description>概述 在开始分析 Kafka 服务端的一些组件之前，来先看看有哪些组件，这些组件又是通过哪个类进行初始化的。 我们在启动Kafka 的时候，通常使用 bin/kafka-server-start.sh config/server.properties 执行 kafka-server-start.sh</description>
    </item>
    
    <item>
      <title>Kafka 服务端（二）KafkaApis</title>
      <link>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BA%8Ckafkaapis/</link>
      <pubDate>Thu, 23 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BA%8Ckafkaapis/</guid>
      <description>1. 概述 根据Kafka 服务端（一）网络层中，KafkaRequestHandler线程 会从 RequestChannel 的requestQueue中取出请求进行处理，并将</description>
    </item>
    
    <item>
      <title>Kafka 服务端（一）网络层</title>
      <link>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%80%E7%BD%91%E7%BB%9C%E5%B1%82/</link>
      <pubDate>Wed, 22 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%80%E7%BD%91%E7%BB%9C%E5%B1%82/</guid>
      <description>1. 概述 Kafka 的网络层使用了 Reactor 模式，其中又有两种类型： date-plane：专门处理来自 客户端 和 broker 的请求 一个 Acceptor 线程，用于接收并处理所有的新连接 N个</description>
    </item>
    
    <item>
      <title>Kafka 生产者（三）Sender 线程</title>
      <link>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%89sender-%E7%BA%BF%E7%A8%8B/</link>
      <pubDate>Wed, 22 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%89sender-%E7%BA%BF%E7%A8%8B/</guid>
      <description>1.概述 在分析了 KafkaProducer 如何把消息存入 RecordAccumulator 中，那么这些ProducerBatch 是如何发送给 Kafka Server 的呢？ 如下图： 当每次调用 RecordAccumulator#append( ) 追加消息的的时候，如果发</description>
    </item>
    
    <item>
      <title>KafkaTools</title>
      <link>/blog/kafkatools/</link>
      <pubDate>Wed, 22 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafkatools/</guid>
      <description>创建 topic &amp;ndash;replication-factor 副本因子数量 &amp;ndash;partitions 分区数量 bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 查看 topic 的信息 topics-with-overrides 查看与集群配置不一样的 topic under-replicated-partitions 查看所有包含失效副本的分区 topics-with-overrides 没有 leader 副本的分区 bin/kafka-topics.sh --zookeeper localhost:2181/kafka</description>
    </item>
    
    <item>
      <title>Kafka 生产者（二）RecordAccumulate</title>
      <link>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8Crecordaccumulate/</link>
      <pubDate>Tue, 21 Apr 2020 10:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8Crecordaccumulate/</guid>
      <description>1.概述 在 Kafka 生产者（一）KafkaProducer 中分析了图中红色区域，也就是说每次调用 send 方法发送消息，都会经过Interceptors、 Serializer</description>
    </item>
    
    <item>
      <title>Kafka 生产者（一）KafkaProducer</title>
      <link>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%80kafkaproducer/</link>
      <pubDate>Mon, 20 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%80kafkaproducer/</guid>
      <description>1. 概述 以Kafka Producer doc 中的例子作为开场( 基于Kafka-2.5.0 )，Producer 用于发消息到 Kafka Broker ，代码如下： public void main(String[] args){ //① 配置 Properties props = new</description>
    </item>
    
    <item>
      <title>Kafka 基础概念</title>
      <link>/blog/kafka-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Sun, 19 Apr 2020 15:37:42 +0800</pubDate>
      
      <guid>/blog/kafka-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</guid>
      <description>Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中。 Consumer：消费者，也就是接收消息的一</description>
    </item>
    
    <item>
      <title>Pulsar - Topic Discovery</title>
      <link>/blog/pulsar-topic-discovery/</link>
      <pubDate>Wed, 04 Mar 2020 22:37:42 +0800</pubDate>
      
      <guid>/blog/pulsar-topic-discovery/</guid>
      <description>Topic Assignment Pulsar 作为多租户消息系统，具有层级命名空间，这个在之前我们也提到了「Tenant &amp;amp; Namespace」相关概念。除去前两层，第三层就是 top</description>
    </item>
    
    <item>
      <title>Pulsar - Message Lifecycle</title>
      <link>/blog/pulsar-message-lifecycle/</link>
      <pubDate>Wed, 04 Mar 2020 13:38:42 +0800</pubDate>
      
      <guid>/blog/pulsar-message-lifecycle/</guid>
      <description>Data Flow Pulsar 集群 1. Brokers + Bookies 前边我们提到过，broker 是各零件之间进行交换的对象。因 Pulsar 为分层架构模式，使用了 BookKeeper 作为额外的存储系统，bookies 就是</description>
    </item>
    
    <item>
      <title>Pulsar VS. Kafka（二）: 以Segment为中心的架构</title>
      <link>/blog/pulsar-vs.-kafka%E4%BA%8C-%E4%BB%A5segment%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Wed, 04 Mar 2020 13:38:42 +0800</pubDate>
      
      <guid>/blog/pulsar-vs.-kafka%E4%BA%8C-%E4%BB%A5segment%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E6%9E%B6%E6%9E%84/</guid>
      <description>Pulsar的分层架构 Pulsar和其他消息系统最根本的不同是采用分层架构。Pulsar集群由两层组成：无状态服务层，由一组接收和传递消息的</description>
    </item>
    
    <item>
      <title>Pulsar VS. Kafka (一): 消息消费模型</title>
      <link>/blog/pulsar-vs.-kafka-%E4%B8%80-%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 04 Mar 2020 13:37:42 +0800</pubDate>
      
      <guid>/blog/pulsar-vs.-kafka-%E4%B8%80-%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B/</guid>
      <description>Pulsar的特性包括消息的持久化存储，多租户，多机房互联互备，加密和安全性等。有比较强的健壮性，高可用性和可预测的延迟等。</description>
    </item>
    
  </channel>
</rss>